{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%html\n",
    "# <!-- This cell makes the font bigger to make it easy to read. Adjust to taste -->\n",
    "# <style>\n",
    "# .cell, .CodeMirror pre{ \n",
    "#     font-size: 150%;\n",
    "#     line-height: 125%;\n",
    "# }\n",
    "# </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSC470 Assignment 2, 2018\n",
    "\n",
    "## Name: Robbie Cook\n",
    "## Due Date: Monday September 24th\n",
    "\n",
    "For assignment 2 you need to implement machine learning algorithm(s) to label faces according to:\n",
    "- sex (male/female)\n",
    "- age (child/teen/adult/senior)\n",
    "- expression (smiling/serious)\n",
    "\n",
    "A data set from MIT is made available, along with code to read the images and labels into `numpy` arrays. \n",
    "These arrays are divided into training, validation, and testing data sets.\n",
    "\n",
    "You may use any machine learning algorithms you like to classify the faces.\n",
    "Techniques you may find useful that we've looked at include:\n",
    "- Decision trees and random forests\n",
    "- Boosting (and AdaBoost in particular)\n",
    "- Support Vector Machines (SVMs)\n",
    "- Face detection (to focus on the key parts of the image)\n",
    "- EigenFaces (for dimensionality reduction)\n",
    "- Neural networks in TensorFlow\n",
    "- CNNs in TensorFlow\n",
    "\n",
    "## Submission Requirements\n",
    "\n",
    "You should submit a version of this Notebook renamed to `YourName.ipynb`, so my submission would be `StevenMills.ipynb`. \n",
    "You can assume that the same libraries that are available in the COSC470 Anaconda environment on the lab machines are available.\n",
    "In particular, you can use numpy, scipy, OpenCV, and TensorFlow.\n",
    "\n",
    "I should be able to open your Notebook and run it. The Notebook should contain the code to construct and train your classifier(s) from the training data (using the validation data appropriately) and then to compute the labels of the training data through a call to `computeLabels`, which has a stub implementation at the end of this notebook. \n",
    "\n",
    "## Marking Scheme\n",
    "\n",
    "A rough marking scheme is given below. This is intentionally fairly open, so that I can give you marks for doing good stuff without having to predetermine what stuff is good.\n",
    "\n",
    "- 10 marks for the discussion of choice of algorithms and training strategy\n",
    "- 10 marks for the explanation and clear implementation\n",
    "- 5 marks for performance\n",
    "\n",
    "### Algorithm Choice and Training\n",
    "\n",
    "I will be looking for a description of the algorithm(s) chosen, why you chose that approach, and how you developed, trained and evaluated your method.\n",
    "You should think about issues such as how to best make use of the training and validation data and how to select parameters for your chosen method.\n",
    "\n",
    "You are not restricted to a single classifier or method. If you find it useful to determine age labels first and then use that to help determine expression, then that is fine. If you want to use an SVM for sex classification, but a boosted classifier for age, that's also fine.\n",
    "However, you should discuss why you chose to use the methods you have chosen.\n",
    "\n",
    "### Explanation and Clear Implementation\n",
    "\n",
    "You should implement your chosen algorithm(s) using the training and validation data sets provided. \n",
    "Jupyter notebooks let you interleave discussion and code, so you should clearly describe how your implementation works.\n",
    "You can include mathematics if needed using \\\\(\\LaTeX\\\\)-style markup as demonstrated in the lecture notebooks.\n",
    "I'll be looking for clear implementations that illustrate good practice in training and evaluation.\n",
    "\n",
    "It is expected that you will make appropriate use of libraries such as OpenCV and TensorFlow where appropriate, but your explanation should your understanding of these tools clear. \n",
    "For example, if you choose to use a convolutional network, you should explain your architecture, how it relates to the code, and give some justification for the various parameters that you need to select when making a CNN.\n",
    "\n",
    "### Performance\n",
    "\n",
    "The last cell of the notebook has a function that takes a face data set and produces labels as a result.\n",
    "You should modify this so that it uses your machine learning algorithms to generate the labels.\n",
    "I will then use these labels to compare your results to the ground truth.\n",
    "I may also shuffle the training, validation, and testing data sets around before running your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Data Set\n",
    "\n",
    "The following code reads the data into training, testing, and validation sets.\n",
    "It assumes that the `.zip` of labelled face data set from the course website has been unzipped into the same directory as the notebook.\n",
    "There are 1997 training images, and 998 each test and training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read in training data and labels\n",
    "\n",
    "# Some useful parsing functions\n",
    "\n",
    "# male/female -> 0/1\n",
    "def parseSexLabel(string):\n",
    "    if (string.startswith('male')):\n",
    "        return 0\n",
    "    if (string.startswith('female')):\n",
    "        return 1\n",
    "    print(\"ERROR parsing sex from \" + string)\n",
    "\n",
    "# child/teen/adult/senior -> 0/1/2/3\n",
    "def parseAgeLabel(string):\n",
    "    if (string.startswith('child')):\n",
    "        return 0\n",
    "    if (string.startswith('teen')):\n",
    "        return 1\n",
    "    if (string.startswith('adult')):\n",
    "        return 2\n",
    "    if (string.startswith('senior')):\n",
    "        return 3\n",
    "    print(\"ERROR parsing age from \" + string)\n",
    "\n",
    "# serious/smiling -> 0/1\n",
    "def parseExpLabel(string):\n",
    "    if (string.startswith('serious')):\n",
    "        return 0\n",
    "    if (string.startswith('smiling') or string.startswith('funny')):\n",
    "        return 1\n",
    "    print(\"ERROR parsing expression from \" + string)\n",
    "\n",
    "# Count number of training instances\n",
    "\n",
    "numTraining = 0\n",
    "\n",
    "for line in open (\"MITFaces/faceDR\"):\n",
    "    numTraining += 1\n",
    "\n",
    "dimensions = 128*128\n",
    "\n",
    "trainingFaces = np.zeros([numTraining,dimensions])\n",
    "trainingSexLabels = np.zeros(numTraining) # Sex - 0 = male; 1 = female\n",
    "trainingAgeLabels = np.zeros(numTraining) # Age - 0 = child; 1 = teen; 2 = male \n",
    "trainingExpLabels = np.zeros(numTraining) # Expression - 0 = serious; 1 = smiling\n",
    "\n",
    "index = 0\n",
    "for line in open (\"MITFaces/faceDR\"):\n",
    "    # Parse the label data\n",
    "    parts = line.split()\n",
    "    trainingSexLabels[index] = parseSexLabel(parts[2])\n",
    "    trainingAgeLabels[index] = parseAgeLabel(parts[4])\n",
    "    trainingExpLabels[index] = parseExpLabel(parts[8])\n",
    "    # Read in the face\n",
    "    fileName = \"MITFaces/rawdata/\" + parts[0]\n",
    "    fileIn = open(fileName, 'rb')\n",
    "    trainingFaces[index,:] = np.fromfile(fileIn, dtype=np.uint8,count=dimensions)/255.0\n",
    "    fileIn.close()\n",
    "    # And move along\n",
    "    index += 1\n",
    "\n",
    "# Count number of validation/testing instances\n",
    "\n",
    "numValidation = 0\n",
    "numTesting = 0\n",
    "\n",
    "# Assume they're all Validation\n",
    "for line in open (\"MITFaces/faceDS\"):\n",
    "    numValidation += 1\n",
    "\n",
    "# And make half of them testing\n",
    "numTesting = int(numValidation/2)\n",
    "numValidation -= numTesting\n",
    "\n",
    "validationFaces = np.zeros([numValidation,dimensions])\n",
    "validationSexLabels = np.zeros(numValidation) # Sex - 0 = male; 1 = female\n",
    "validationAgeLabels = np.zeros(numValidation) # Age - 0 = child; 1 = teen; 2 = male \n",
    "validationExpLabels = np.zeros(numValidation) # Expression - 0 = serious; 1 = smiling\n",
    "\n",
    "testingFaces = np.zeros([numTesting,dimensions])\n",
    "testingSexLabels = np.zeros(numTesting) # Sex - 0 = male; 1 = female\n",
    "testingAgeLabels = np.zeros(numTesting) # Age - 0 = child; 1 = teen; 2 = male \n",
    "testingExpLabels = np.zeros(numTesting) # Expression - 0 = serious; 1 = smiling\n",
    "\n",
    "index = 0\n",
    "for line in open (\"MITFaces/faceDS\"):\n",
    "    # Parse the label data\n",
    "    if (index < numTesting):\n",
    "        testingSexLabels[index] = parseSexLabel(parts[2])\n",
    "        testingAgeLabels[index] = parseAgeLabel(parts[4])\n",
    "        testingExpLabels[index] = parseExpLabel(parts[8])\n",
    "        # Read in the face\n",
    "        fileName = \"MITFaces/rawdata/\" + parts[0]\n",
    "        fileIn = open(fileName, 'rb')\n",
    "        testingFaces[index,:] = np.fromfile(fileIn, dtype=np.uint8,count=dimensions)/255.0\n",
    "        fileIn.close()\n",
    "    else:\n",
    "        vIndex = index - numTesting\n",
    "        validationSexLabels[vIndex] = parseSexLabel(parts[2])\n",
    "        validationAgeLabels[vIndex] = parseAgeLabel(parts[4])\n",
    "        validationExpLabels[vIndex] = parseExpLabel(parts[8])\n",
    "        # Read in the face\n",
    "        fileName = \"MITFaces/rawdata/\" + parts[0]\n",
    "        fileIn = open(fileName, 'rb')\n",
    "        validationFaces[vIndex,:] = np.fromfile(fileIn, dtype=np.uint8,count=dimensions)/255.0\n",
    "        fileIn.close()\n",
    "        \n",
    "    # And move along\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My work\n",
    "\n",
    "First, I had to clean the data (MITFaces/faceDS, MITFaces/faceDR), because the parsing data above didn't work for lines such as `1232 (_missing descriptor)`. I got an index out of bound error `testingAgeLabels[index] = parseAgeLabel(parts[4])`. To remedy this, I simply removed the entries from the data file which caused the error. This meant I didn't have to mess around with the already provided, good, code.\n",
    "\n",
    "I then decided for the first part of the assignment, which was gender classification, to use a random forest. The Sklearn RandomForest implementation is a bagging technique for decision trees. The Random Forest algorithm uses a voting system of a set of trees built by training on different samples of the training population. Decision trees themselves are built using a greedy algorithm which selects optimal split points on a set of data to classify data based on its features.\n",
    "\n",
    "I used sklearn, and tensorflow for my implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Random forest on sex classification\n",
      "\n",
      "Accuracy on training set: 99.29894842263394%\n",
      "Accuracy on validation set: 100.0%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(trainingFaces, trainingSexLabels)\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(\"Random forest on sex classification\\n\")\n",
    "print(\"Accuracy on training set: {}%\".format(rfc.score(trainingFaces, trainingSexLabels)*100))\n",
    "print(\"Accuracy on validation set: {}%\".format(rfc.score(validationFaces, validationSexLabels)*100))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, random forest to classify age groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Random forest on age classification\n",
      "\n",
      "Accuracy on training set: 99.24887330996495%\n",
      "Accuracy on validation set: 100.0%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(trainingFaces, trainingAgeLabels)\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(\"Random forest on age classification\\n\")\n",
    "print(\"Accuracy on training set: {}%\".format(rfc.score(trainingFaces, trainingAgeLabels)*100))\n",
    "print(\"Accuracy on validation set: {}%\".format(rfc.score(validationFaces, validationAgeLabels)*100))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then for expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Random forest on expression classification\n",
      "\n",
      "Accuracy on training set: 98.79819729594391%\n",
      "Accuracy on validation set: 100.0%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(trainingFaces, trainingExpLabels)\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(\"Random forest on expression classification\\n\")\n",
    "print(\"Accuracy on training set: {}%\".format(rfc.score(trainingFaces, trainingExpLabels)*100))\n",
    "print(\"Accuracy on validation set: {}%\".format(rfc.score(validationFaces, validationExpLabels)*100))\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was very surprised at how well the Random Forest algorithm performed on this dataset. It gets very close to 100% accuracy most times. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Convolutional Neural Network Solution\n",
    "\n",
    "\n",
    "## Network\n",
    "\n",
    "\n",
    "This CNN is based off the TensorFlow Keras CNN for basic MNIST found at `https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py`. I was not sure about the exact dimensions of the image for resizing for the CNN, so I ended up reshaping to a 1997 x 4 x 64 x 64 image as input. I decided to choose this network because the task of MNist is similar to the tasks given, and it is a network to establish a baseline for better networks.\n",
    "\n",
    "2D Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (these take ages)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv1D,Conv2D,MaxPooling1D,MaxPooling2D,Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def runCNN(x_train, y_train, x_test, y_test):\n",
    "    num_classes = len(set(y_train))\n",
    "    print(\"Num classes:\", num_classes)\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    x_train = x_train.reshape(len(x_train), 64, 64, 4)\n",
    "    x_test = x_test.reshape(len(x_test), 64, 64, 4)\n",
    "\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (2, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              epochs=10, \n",
    "              verbose=1,\n",
    "              batch_size=128)\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    trainingScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "#     print('Test loss:', score[0], ' (categorical crossentropy)')\n",
    "    print('Training accuracy: {}%'.format(trainingScore[1]*100))\n",
    "    print('Test accuracy: {}%'.format(score[1]*100));\n",
    "    \n",
    "    print()\n",
    "    print('Example prediction', x_train[0], y_train, model.predict([x_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 2\n",
      "Epoch 1/10\n",
      "1997/1997 [==============================] - 31s 15ms/step - loss: 0.8077 - acc: 0.5473\n",
      "Epoch 2/10\n",
      "1997/1997 [==============================] - 29s 15ms/step - loss: 0.6645 - acc: 0.6069\n",
      "Epoch 3/10\n",
      " 256/1997 [==>...........................] - ETA: 26s - loss: 0.6471 - acc: 0.6250"
     ]
    }
   ],
   "source": [
    "runCNN(x_train=trainingFaces, y_train=trainingSexLabels, x_test=validationFaces, y_test=validationSexLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should get close to 100% accuracy every time on the test data, for this task, which is really good. 35 epochs is a lot for a CNN though, especially since MNist can be solved in under 12 epochs with a similar network and has 60000 images. \n",
    "Sometimes this program slows down my machine so much that it can't function (before training), and I suspect that it could be something to do with the memory allocation required when reshaping the faces.\n",
    "If this happens, please run this code in another environment.\n",
    "\n",
    "## Age Labels\n",
    "\n",
    "This just uses the same CNN as the above, but sets the age labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 4\n",
      "Epoch 1/10\n",
      "1997/1997 [==============================] - 3s 1ms/step - loss: 0.9158 - acc: 0.6945\n",
      "Epoch 2/10\n",
      "1997/1997 [==============================] - 2s 888us/step - loss: 0.8174 - acc: 0.7126\n",
      "Epoch 3/10\n",
      "1997/1997 [==============================] - 2s 889us/step - loss: 0.7202 - acc: 0.7196\n",
      "Epoch 4/10\n",
      "1997/1997 [==============================] - 2s 888us/step - loss: 0.6765 - acc: 0.7191\n",
      "Epoch 5/10\n",
      "1997/1997 [==============================] - 2s 895us/step - loss: 0.6551 - acc: 0.7396\n",
      "Epoch 6/10\n",
      "1997/1997 [==============================] - 2s 892us/step - loss: 0.6009 - acc: 0.7591\n",
      "Epoch 7/10\n",
      "1997/1997 [==============================] - 2s 891us/step - loss: 0.5559 - acc: 0.7847\n",
      "Epoch 8/10\n",
      "1997/1997 [==============================] - 2s 912us/step - loss: 0.5623 - acc: 0.7782\n",
      "Epoch 9/10\n",
      "1997/1997 [==============================] - 2s 969us/step - loss: 0.4877 - acc: 0.8152\n",
      "Epoch 10/10\n",
      "1997/1997 [==============================] - 2s 897us/step - loss: 0.4530 - acc: 0.8247\n",
      "Training accuracy: 81.47220831396106%\n",
      "Test accuracy: 0.0%\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_22_input to have 4 dimensions, but got array with shape (4, 64, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b76a3fb1d59e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingFaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingAgeLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidationFaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidationAgeLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-afbc0aa406a4>\u001b[0m in \u001b[0;36mrunCNN\u001b[0;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example prediction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1471\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    180\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_22_input to have 4 dimensions, but got array with shape (4, 64, 64)"
     ]
    }
   ],
   "source": [
    "runCNN(x_train=trainingFaces, y_train=trainingAgeLabels, x_test=validationFaces, y_test=validationAgeLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes: 2\n",
      "Epoch 1/10\n",
      "1997/1997 [==============================] - 2s 1ms/step - loss: 0.7175 - acc: 0.5258\n",
      "Epoch 2/10\n",
      "1997/1997 [==============================] - 2s 884us/step - loss: 0.6784 - acc: 0.5759\n",
      "Epoch 3/10\n",
      "1997/1997 [==============================] - 2s 890us/step - loss: 0.6673 - acc: 0.5794\n",
      "Epoch 4/10\n",
      "1997/1997 [==============================] - 2s 884us/step - loss: 0.6564 - acc: 0.6360\n",
      "Epoch 5/10\n",
      "1997/1997 [==============================] - 2s 881us/step - loss: 0.6132 - acc: 0.6555\n",
      "Epoch 6/10\n",
      "1997/1997 [==============================] - 2s 886us/step - loss: 0.5661 - acc: 0.7121\n",
      "Epoch 7/10\n",
      "1997/1997 [==============================] - 2s 889us/step - loss: 0.5710 - acc: 0.7211\n",
      "Epoch 8/10\n",
      "1997/1997 [==============================] - 2s 945us/step - loss: 0.5230 - acc: 0.7541\n",
      "Epoch 9/10\n",
      "1997/1997 [==============================] - 2s 891us/step - loss: 0.5161 - acc: 0.7511\n",
      "Epoch 10/10\n",
      "1997/1997 [==============================] - 2s 892us/step - loss: 0.4863 - acc: 0.7827\n",
      "Training accuracy: 77.56634953025585%\n",
      "Test accuracy: 100.0%\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_12_input to have 4 dimensions, but got array with shape (16384, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-34ff6c810eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingFaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainingExpLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidationFaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidationExpLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-528726824b60>\u001b[0m in \u001b[0;36mrunCNN\u001b[0;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Example prediction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidationFaces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidationSexLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidationFaces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1471\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    180\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_12_input to have 4 dimensions, but got array with shape (16384, 1)"
     ]
    }
   ],
   "source": [
    "runCNN(x_train=trainingFaces, y_train=trainingExpLabels, x_test=validationFaces, y_test=validationExpLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to evaluate your submission.\n",
    "\n",
    "def computeLabels(faceData):\n",
    "    n, d = faceData.shape\n",
    "    # Zero arrays for the labels, should be able to do better than this\n",
    "    estSexLabels = np.zeros(n)\n",
    "    estAgeLabels = np.zeros(n)\n",
    "    estExpLabels = np.zeros(n)\n",
    "    return estSexLabels, estAgeLabels, estExpLabels\n",
    "\n",
    "estS, estA, estE = computeLabels(testData)\n",
    "# I'll do stuff with the above to evaluate the accuracy of your methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
